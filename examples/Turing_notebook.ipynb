{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34a94e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from fbpinns.domains import RectangularDomainND\n",
    "from fbpinns.problems import Problem\n",
    "from fbpinns.decompositions import RectangularDecompositionND\n",
    "from fbpinns.networks import FCN\n",
    "from fbpinns.constants import Constants, get_subdomain_ws\n",
    "from fbpinns.trainers import FBPINNTrainer, PINNTrainer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "697f9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuringSystem2D(Problem):\n",
    "    \"\"\"Solves the Turing reaction-diffusion system in 2D:\n",
    "        ∂u/∂t = Du∇²u + f(u,v)\n",
    "        ∂v/∂t = Dv∇²v + g(u,v)\n",
    "        \n",
    "        where f and g are the reaction terms from the Schnakenberg model:\n",
    "        f(u,v) = a - u + u²v\n",
    "        g(u,v) = b - u²v\n",
    "        \n",
    "        with periodic boundary conditions and random initial conditions\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def init_params(Du=1.0, Dv=10.0, a=0.1, b=0.9):\n",
    "        static_params = {\n",
    "            \"dims\": (2, 3),  # 2 outputs (u,v), 3 inputs (x,y,t)\n",
    "            \"Du\": Du,        # Diffusion coefficient for u\n",
    "            \"Dv\": Dv,        # Diffusion coefficient for v\n",
    "            \"a\": a,          # Reaction parameter\n",
    "            \"b\": b,          # Reaction parameter\n",
    "        }\n",
    "        return static_params, {}\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_constraints(all_params, domain, key, sampler, batch_shapes):\n",
    "        # Split random keys\n",
    "        key1, key2 = jax.random.split(key)\n",
    "        \n",
    "        # Sample interior points for PDE\n",
    "        x_batch_phys = domain.sample_interior(all_params, key1, sampler, batch_shapes[0])\n",
    "        \n",
    "        # Sample initial condition points (t=0)\n",
    "        x_batch_init = domain.sample_interior(all_params, key2, sampler, batch_shapes[1])\n",
    "        # Set time coordinate to 0 for initial conditions\n",
    "        x_batch_init = x_batch_init.at[:,2].set(0.0)\n",
    "        \n",
    "        # Required derivatives for PDE residuals\n",
    "        required_ujs_phys = [\n",
    "            (0, ()),      # u value\n",
    "            (0, (0,0)),  # ∂²u/∂x²\n",
    "            (0, (1,1)),  # ∂²u/∂y²\n",
    "            (0, (2,)),   # ∂u/∂t\n",
    "            (1, ()),      # v value\n",
    "            (1, (0,0)),  # ∂²v/∂x²\n",
    "            (1, (1,1)),  # ∂²v/∂y²\n",
    "            (1, (2,)),   # ∂v/∂t\n",
    "        ]\n",
    "        \n",
    "        # Required derivatives for initial conditions (no derivatives needed)\n",
    "        required_ujs_init = [\n",
    "            (0, ()),     # u value\n",
    "            (1, ()),     # v value\n",
    "        ]\n",
    "        \n",
    "        return [[x_batch_phys, required_ujs_phys], [x_batch_init, required_ujs_init]]\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_fn(all_params, constraints):\n",
    "        Du = all_params[\"static\"][\"problem\"][\"Du\"]\n",
    "        Dv = all_params[\"static\"][\"problem\"][\"Dv\"]\n",
    "        a = all_params[\"static\"][\"problem\"][\"a\"]\n",
    "        b = all_params[\"static\"][\"problem\"][\"b\"]\n",
    "        \n",
    "        # Unpack constraints - each constraint is a list [x_batch, *ujs]\n",
    "        x_batch_phys = constraints[0][0]\n",
    "        x_batch_init = constraints[1][0]\n",
    "        \n",
    "        # Get derivatives from ujs\n",
    "        derivs_phys = constraints[0][1:]  # Skip x_batch\n",
    "        derivs_init = constraints[1][1:]  # Skip x_batch\n",
    "        \n",
    "        # Get function values and derivatives\n",
    "        u = derivs_phys[0]      # u value\n",
    "        ux = derivs_phys[1]     # ∂u/∂x\n",
    "        uy = derivs_phys[2]     # ∂u/∂y\n",
    "        ut = derivs_phys[3]     # ∂u/∂t\n",
    "        v = derivs_phys[4]      # v value\n",
    "        vx = derivs_phys[5]     # ∂v/∂x\n",
    "        vy = derivs_phys[6]     # ∂v/∂y\n",
    "        vt = derivs_phys[7]     # ∂v/∂t\n",
    "        \n",
    "        # Compute Laplacians using the provided derivatives\n",
    "        laplacian_u = ux + uy  # ∂²u/∂x² + ∂²u/∂y²\n",
    "        laplacian_v = vx + vy  # ∂²v/∂x² + ∂²v/∂y²\n",
    "        \n",
    "        # Reaction terms (Schnakenberg model)\n",
    "        f = a - u + u**2 * v\n",
    "        g = b - u**2 * v\n",
    "        \n",
    "        # PDE residuals\n",
    "        residual_u = ut - Du * laplacian_u - f\n",
    "        residual_v = vt - Dv * laplacian_v - g\n",
    "        \n",
    "        # Initial conditions\n",
    "        u_init = derivs_init[0]  # u value at t=0\n",
    "        v_init = derivs_init[1]  # v value at t=0\n",
    "        \n",
    "        # Random initial conditions centered around the homogeneous steady state\n",
    "        key = jax.random.PRNGKey(0)\n",
    "        u0 = a + b + jax.random.normal(key, u_init.shape) * 0.1\n",
    "        v0 = b/((a + b)**2) + jax.random.normal(key, v_init.shape) * 0.1\n",
    "        \n",
    "        # Compute losses\n",
    "        init_loss = jnp.mean((u_init - u0)**2 + (v_init - v0)**2)\n",
    "        pde_loss = jnp.mean(residual_u**2 + residual_v**2)\n",
    "        \n",
    "        # Weight the losses\n",
    "        total_loss = pde_loss + 10.0 * init_loss\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def exact_solution(all_params, x_batch, batch_shape):\n",
    "        # For Turing patterns, there is no exact solution\n",
    "        # Return homogeneous steady state as reference\n",
    "        a = all_params[\"static\"][\"problem\"][\"a\"]\n",
    "        b = all_params[\"static\"][\"problem\"][\"b\"]\n",
    "        \n",
    "        u_ss = a + b\n",
    "        v_ss = b/((a + b)**2)\n",
    "        \n",
    "        # Reshape to match the expected output shape\n",
    "        return jnp.stack([\n",
    "            u_ss * jnp.ones(x_batch.shape[0]),\n",
    "            v_ss * jnp.ones(x_batch.shape[0])\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "899e3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain setup\n",
    "Lx, Ly = 10.0, 10.0  # Smaller domain for better pattern formation\n",
    "T = 5.0              # Shorter time range\n",
    "\n",
    "subdomain_xs = [np.linspace(-Lx/2, Lx/2, 5), \n",
    "                np.linspace(-Ly/2, Ly/2, 5), \n",
    "                np.linspace(0, T, 5)]\n",
    "subdomain_ws = get_subdomain_ws(subdomain_xs, 1.9)\n",
    "\n",
    "c = Constants(\n",
    "    run=\"turing_pattern\",\n",
    "    domain=RectangularDomainND,\n",
    "    domain_init_kwargs=dict(\n",
    "        xmin=np.array([-Lx/2, -Ly/2, 0]),\n",
    "        xmax=np.array([Lx/2, Ly/2, T]),\n",
    "    ),\n",
    "    problem=TuringSystem2D,\n",
    "    problem_init_kwargs=dict(\n",
    "        Du=0.1,     # Smaller diffusion coefficient for u\n",
    "        Dv=2.0,     # Larger diffusion coefficient ratio\n",
    "        a=0.1,      # Reaction parameter a\n",
    "        b=0.9,      # Reaction parameter b\n",
    "    ),\n",
    "    decomposition=RectangularDecompositionND,\n",
    "    decomposition_init_kwargs=dict(\n",
    "        subdomain_xs=subdomain_xs,\n",
    "        subdomain_ws=subdomain_ws,\n",
    "        unnorm=(0., 1.),\n",
    "    ),\n",
    "    network=FCN,\n",
    "    network_init_kwargs=dict(\n",
    "        layer_sizes=[3, 64, 64, 32, 2],  # Deeper network\n",
    "    ),\n",
    "    ns=((80,80,40), (80,80,1)),  # More points for better resolution\n",
    "    n_test=(100,100,20),         # Test resolution\n",
    "    n_steps=15000,               # More training steps\n",
    "    optimiser_kwargs=dict(learning_rate=5e-4),  # Lower learning rate\n",
    "    summary_freq=200,\n",
    "    test_freq=200,\n",
    "    model_save_freq=10000,\n",
    "    show_figures=True,\n",
    "    save_figures=False,\n",
    "    clear_output=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c8b09ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2025-05-28 15:53:44 - <fbpinns.constants.Constants object at 0x7f88021ef040>\n",
      "run: turing_pattern\n",
      "domain: <class 'fbpinns.domains.RectangularDomainND'>\n",
      "domain_init_kwargs: {'xmin': array([-5., -5.,  0.]), 'xmax': array([5., 5., 5.])}\n",
      "problem: <class '__main__.TuringSystem2D'>\n",
      "problem_init_kwargs: {'Du': 0.1, 'Dv': 2.0, 'a': 0.1, 'b': 0.9}\n",
      "decomposition: <class 'fbpinns.decompositions.RectangularDecompositionND'>\n",
      "decomposition_init_kwargs: {'subdomain_xs': [array([-5. , -2.5,  0. ,  2.5,  5. ]), array([-5. , -2.5,  0. ,  2.5,  5. ]), array([0.  , 1.25, 2.5 , 3.75, 5.  ])], 'subdomain_ws': [array([4.75, 4.75, 4.75, 4.75, 4.75]), array([4.75, 4.75, 4.75, 4.75, 4.75]), array([2.375, 2.375, 2.375, 2.375, 2.375])], 'unnorm': (0.0, 1.0)}\n",
      "network: <class 'fbpinns.networks.FCN'>\n",
      "network_init_kwargs: {'layer_sizes': [3, 64, 64, 32, 2]}\n",
      "n_steps: 15000\n",
      "scheduler: <class 'fbpinns.schedulers.AllActiveSchedulerND'>\n",
      "scheduler_kwargs: {}\n",
      "ns: ((80, 80, 40), (80, 80, 1))\n",
      "n_test: (100, 100, 20)\n",
      "sampler: grid\n",
      "optimiser: <function adam at 0x7f892ac2b910>\n",
      "optimiser_kwargs: {'learning_rate': 0.0005}\n",
      "seed: 0\n",
      "summary_freq: 200\n",
      "test_freq: 200\n",
      "model_save_freq: 10000\n",
      "show_figures: True\n",
      "save_figures: False\n",
      "clear_output: True\n",
      "hostname: bbkevin\n",
      "\n",
      "[INFO] 2025-05-28 15:53:44 - Total number of trainable parameters:\n",
      "[INFO] 2025-05-28 15:53:44 - \tnetwork: 6,562\n",
      "[INFO] 2025-05-28 15:53:44 - Total number of constraints: 2\n",
      "[INFO] 2025-05-28 15:53:44 - Computing exact solution..\n",
      "[INFO] 2025-05-28 15:53:44 - Computing done\n",
      "[INFO] 2025-05-28 15:53:44 - [i: 0/15000] Compiling update step..\n",
      "[INFO] 2025-05-28 15:53:44 - x_batch\n",
      "[INFO] 2025-05-28 15:53:44 - (256000, 3), float32, JVPTracer\n",
      "[INFO] 2025-05-28 15:53:44 - x_batch\n",
      "[INFO] 2025-05-28 15:53:44 - (256000, 3), float32, JVPTracer\n",
      "[INFO] 2025-05-28 15:53:44 - x_batch\n",
      "[INFO] 2025-05-28 15:53:44 - (256000, 3), float32, JVPTracer\n",
      "[INFO] 2025-05-28 15:53:44 - x_batch\n",
      "[INFO] 2025-05-28 15:53:44 - (6400, 3), float32, DynamicJaxprTracer\n",
      "[INFO] 2025-05-28 15:53:44 - [i: 0/15000] Compiling done (0.66 s)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'IPython.display' has no attribute 'display_available'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train using custom Turing trainer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m run \u001b[38;5;241m=\u001b[39m PINNTrainer(c)\n\u001b[0;32m----> 3\u001b[0m all_params \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FBPINNs/fbpinns/trainers.py:851\u001b[0m, in \u001b[0;36mPINNTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(c\u001b[38;5;241m.\u001b[39mn_steps):\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    849\u001b[0m         \u001b[38;5;66;03m# report initial model\u001b[39;00m\n\u001b[1;32m    850\u001b[0m         u_test_losses, start1, report_time \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 851\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_test_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mu_exact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_opt_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_fns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mactive_opt_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlossval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;66;03m# take a training step\u001b[39;00m\n\u001b[1;32m    858\u001b[0m     lossval, active_opt_states, active_params \u001b[38;5;241m=\u001b[39m update(active_opt_states,\n\u001b[1;32m    859\u001b[0m                                active_params, static_params_dynamic,\n\u001b[1;32m    860\u001b[0m                                constraints)\u001b[38;5;66;03m# note compiled function only accepts dynamic arguments\u001b[39;00m\n",
      "File \u001b[0;32m~/FBPINNs/fbpinns/trainers.py:909\u001b[0m, in \u001b[0;36mPINNTrainer._report\u001b[0;34m(self, i, pstep, fstep, u_test_losses, start0, start1, report_time, u_exact, x_batch_test, all_params, all_opt_states, model_fns, problem, active_opt_states, active_params, x_batch, lossval)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;66;03m# take test step\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_:\n\u001b[0;32m--> 909\u001b[0m     u_test_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_batch_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_exact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_test_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_fns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;66;03m# save model\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_save_:\n",
      "File \u001b[0;32m~/FBPINNs/fbpinns/trainers.py:937\u001b[0m, in \u001b[0;36mPINNTrainer._test\u001b[0;34m(self, x_batch_test, u_exact, u_test_losses, x_batch, i, pstep, fstep, start0, all_params, model_fns, problem)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;66;03m# create figures\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m (c\u001b[38;5;241m.\u001b[39mtest_freq \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 937\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[43mplot_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPINN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstatic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproblem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdims\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_batch_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_exact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_raw_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_figs(i, fs)\n",
      "File \u001b[0;32m~/FBPINNs/fbpinns/plot_trainer.py:25\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(trainer, dims, *args)\u001b[0m\n\u001b[1;32m     23\u001b[0m nx \u001b[38;5;241m=\u001b[39m dims[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer \u001b[38;5;129;01min\u001b[39;00m _plotters \u001b[38;5;129;01mand\u001b[39;00m nx \u001b[38;5;129;01min\u001b[39;00m _plotters[trainer]:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_plotters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "File \u001b[0;32m~/FBPINNs/fbpinns/plot_trainer_1D.py:29\u001b[0m, in \u001b[0;36m_to_numpy.<locals>.wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     28\u001b[0m     args \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m a: np\u001b[38;5;241m.\u001b[39marray(a) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, jnp\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m a, args)\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FBPINNs/fbpinns/plot_trainer_3D.py:69\u001b[0m, in \u001b[0;36mplot_3D_PINN\u001b[0;34m(x_batch_test, u_exact, u_test, u_raw_test, x_batch, all_params, i, n_test)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;129m@_to_numpy\u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot_3D_PINN\u001b[39m(x_batch_test, u_exact, u_test, u_raw_test, x_batch, all_params, i, n_test):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Clear previous output in Jupyter\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_available\u001b[49m:\n\u001b[1;32m     70\u001b[0m         display\u001b[38;5;241m.\u001b[39mclear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Get plot limits\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'IPython.display' has no attribute 'display_available'"
     ]
    }
   ],
   "source": [
    "# Train using custom Turing trainer\n",
    "run = PINNTrainer(c)\n",
    "all_params = run.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beecc2aa-a1f6-4585-bb51-16a809355f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039cf87-5e27-49a0-bdc4-931f5aca3461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
